import cv2
import mediapipe as mp
import pyautogui
import threading
import time

# Initialize video capture and parameters
cap = cv2.VideoCapture(0)
cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)  # Lower resolution for better performance
cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)

mp_hands = mp.solutions.hands
hand_detector = mp_hands.Hands(max_num_hands=1, min_detection_confidence=0.75, min_tracking_confidence=0.5)
drawing_utils = mp.solutions.drawing_utils

screen_width, screen_height = pyautogui.size()

plocx, plocy = 0, 0
clocx, clocy = 0, 0
smoothening = 5  # Lower smoothening factor for better responsiveness

frame = None
ret = False

def capture_frames():
    global frame, ret
    while True:
        ret, frame = cap.read()

# Start a separate thread for capturing video frames
thread = threading.Thread(target=capture_frames)
thread.daemon = True
thread.start()

def calculate_distance(x1, y1, x2, y2):
    return ((x2 - x1) ** 2 + (y2 - y1) ** 2) ** 0.5

hands = None
frame_counter = 0

while True:
    if not ret or frame is None:
        continue

    frame_counter += 1

    frame = cv2.flip(frame, 1)
    frame_height, frame_width, _ = frame.shape

    if frame_counter % 10 == 0:  # Process every 10th frame to reduce load
        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        output = hand_detector.process(rgb_frame)
        hands = output.multi_hand_landmarks

    if hands:
        for hand in hands:
            drawing_utils.draw_landmarks(frame, hand, mp_hands.HAND_CONNECTIONS)
            landmarks = hand.landmark

            index_x, index_y = 0, 0
            thumb_x, thumb_y = 0, 0
            middle_x, middle_y = 0, 0
            ring_x, ring_y = 0, 0
            pinky_x, pinky_y = 0, 0

            for id, landmark in enumerate(landmarks):
                x = int(landmark.x * frame_width)
                y = int(landmark.y * frame_height)

                if id == 8:
                    index_x = (screen_width / frame_width) * x
                    index_y = (screen_height / frame_height) * y
                    clocx = plocx + (index_x - plocx) / smoothening
                    clocy = plocy + (index_y - plocy) / smoothening
                    pyautogui.moveTo(clocx, clocy)
                    plocx, plocy = clocx, clocy

                if id == 4:
                    thumb_x = (screen_width / frame_width) * x
                    thumb_y = (screen_height / frame_height) * y

                if id == 12:
                    middle_x = (screen_width / frame_width) * x
                    middle_y = (screen_height / frame_height) * y

                if id == 16:
                    ring_x = (screen_width / frame_width) * x
                    ring_y = (screen_height / frame_height) * y

                if id == 20:
                    pinky_x = (screen_width / frame_width) * x
                    pinky_y = (screen_height / frame_height) * y

            if calculate_distance(index_x, index_y, thumb_x, thumb_y) < 40:
                pyautogui.click()
                time.sleep(0.3)  # Add delay to avoid multiple clicks

            if abs(middle_y - index_y) < 70:
                if middle_y < index_y:
                    pyautogui.scroll(5)
                else:
                    pyautogui.scroll(-5)

            if abs(ring_y - index_y) < 70:
                pyautogui.rightClick()
                time.sleep(0.3)  # Add delay to avoid multiple right clicks

            if abs(pinky_y - index_y) < 70:
                if pinky_y < index_y:
                    pyautogui.press('volumeup')
                else:
                    pyautogui.press('volumedown')

    cv2.imshow('Virtual Mouse', frame)

    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

cap.release()
cv2.destroyAllWindows()
